#+TITLE: Advanced graph topics
#+SUBTITLE: Software Engineering Topics
#+INCLUDE: "../navbar.html" export html
#+OPTIONS: toc:nil
#+OPTIONS: num:nil
#+LaTeX_HEADER: \usepackage{tikz}
#+LATeX_HEADER: \usepackage{pgfplots}

* Connectivity
  The form and intensity which nodes are connected to each other is an important
  factor when designing graph algorithms. Usually, a graph is implemented either
  as an adjacency list or a matrix, if every node  is connected to each other
  (the graph is /strongly/ connected), then one could use a $\Theta(n^2)$ space
  matrix representation as the presence of edges can be checke in $\Theta(1)$ time,
  and retrieving a current node's neighbor is returned in $\Theta(n)$ time.

  The degree $d_a$, is the notation which measures how connected is node $a$. For
  /sparse/ graphs, when the degrees of the nodes are usually smaller than $n$
  an $\Theta(n+m)$ space adjacency list representation is a better fit. Notice,
  in such representation, the sum of all degrees for every node, assuming undirected
  edges, is:
  \[ \sum_{i \in N} d_i = 2m \]

  As the same edge $(a, b)$ exists in $adj[a]$ and $adj[b]$. Retrieving
  neighbors of $a$ or checking the presence of an edge can be made in
  $\Theta(d_a)$, by simply looking up $adj[a]$. Notice, that depending on how
  sparse a graph is, traversing it can amount to a significant time reduction
  when using the adjancency list as opposed to the matrix representation.
  Imagine in a tree-traversal algorithm where the neighbors of each node are retrieved,
  then we would spend $\Theta(m) = \Theta(n)$ time for adjacency lists while
  $\Theta(n^2)$ for matrixes.

  For a practical example on the complexity implications of the two implementations
  the LeetCode solution and discution for [[https://leetcode.com/problems/frog-position-after-t-seconds/][Frog Position After T Seconds - 1377]]
  can be found in the [[file:treesgraphs.html][Trees and graphs]] page. 

** Connected components
  The definition of a connected component is the set of nodes reacheable from a
  particular initial node $n_i$, one can also think about a connected component as
  the set of nodes in a search tree produced by a complete execution of BFS
  or DFS algorithm. Another way to understand how one can explore nodes on a
  graph $G=(E, N)$ forming a connected component $C_{0}$ starting at node $0$ is:
  
  #+begin_src python
  def explore_graph(E, N):
    C = {0}
    while ((a, b) in E and
  	 a in C and
  	 b not in C):
      C.append(b)
  #+end_src
    
  Notice we are also solving the connectivity problem, by defining every node $i$
  that is reachable from node $0$. Notice, it is also trivial to define the path
  itself that lead to node $i$, as we know at which iteration $i$ was added to $C$
  and therefore we also know the neighboring node which was in $C$, so we can always
  trace back to node $0$ by keeping the /"parent"/ of each node in $C$. The order
  of which the edges $(a,b)$ will be fetched from the graph $G$ can be defined
  by DFS or BFS algorithm.
  
  We mentioned about connected components relative to a starting node, but what
  about the set of connected components of a graph. One can say:
  
    //""For any two nodes $a$ and $b$ in a graph, their connected components are
    either identical or disjoint""//
  
  *proof:* assume there are two nodes $a$ and $b$ which their connected
  components are different and connected. That means that starting from $a$, we would
  obtain $C_a$ and starting from $b$ we would obtain $C_b$, if they are different
  that means that there are nodes that exist at least one node $c$ which is in
  w.l.o.g. in $C_a$ but not in $C_b$. That means, there is no path from $b$ to
  $c$, however, as there is a path from $b$ to $a$ and from $a$ to $c$, then there
  must be a path from $b$ to $c$, which is a contradiction.

** Complexity in Graph Algorithms
  Normally, the running time of graph algorithms are expressed in terms of
  $(n=|N|, e=|E|)$ for $G(N,E)$. However, it is not always obvious which complexity
  to prioritize, will an algorithm in $O(n^3)$ or $O(e^2)$ run faster? Well, it
  depends on the relationship between $n$ and $e$. If we consider a single
  connected component, there should be at least $n-1$, and at most $C^{n}_{2} < n^2$
  edges. Therefore, for trees $O(e^2)$ is better, while for strongly connected
  graphs $O(n^3)$ is.

* Heaps
  Heaps are balanced binary trees that such that the parent has always the min or max
  of all it's descendents. Balanced or height-balanced binary trees are nearly complete trees
  that keep the height of every node's left and right branch balanced, i.e. with
  equal or difference of 1. One of the benefits of balanced trees is it's height
  is $log(n)$ on it's the size, and so takes $log(n)$ to go from the root to a leaf.
  Such trees are balanced they can be represented as an array, of elements:
  $${13,11,9,8,10,6,5,7,4,3,10}$$

  where the $heap[i]$'s:
  
  + parent is $heap[\lfloor i/2 \rfloor]$,
  + left node is $heap[2i]$, and
  + right node is $heap[2i+1]$

#+begin_src latex :exports results :results raw file :file simpleheap.png :output-dir ../img
  \resizebox{0.5\textwidth}{!}{%
    \begin{tikzpicture}[scale=1,nodes={draw, circle}, ->]
      \node{13}
      child { node{11}
	child { node {8}
	 child { node {4} }
	 child { node {3} }
	 }
	child[missing]
	child { node {10}
	child { node {10} }
        child[missing] 
      }
      }
      child[missing]
      child[missing]
      child { node {9}
	child { node {6} }
	child { node {5} }
      };
   \end{tikzpicture}
       }%
#+end_src

#+RESULTS:
[[file:../img/simpleheap.png]]

  As we can see in the structure of this max-heap, the largest value is at the root
  and the smallest value is a leaf, 3. Notice that a child can also have the same
  value as it's parent, such as in the case of 10. Notice that the array representing
  the heap, must not necessarily be sorted. However, a sorted array is necessarily
  a heap, as it respects the heap property of:
  
  //""...the parent has always the min or max of all it's descendents.""//
  
  Imagine a sorted array representing a min-heap, then for every node $heap[i]$
  all it's descendents which are at positions $\ge 2i$, and have by definition bigger
  values than $heap[i]$, likewise all ascendants are at positions $\le i/2$.
  
  We can also check that it takes at most $\lfloor log_2(10)\rfloor = 3$ iterations
  from any path from the root to a leaf. To preserve a heap under change we must
  be able to preserve the property mentioned above. Imagine we were given the
  following array:
  $${13,7,9,8,10,6,5,7,4,3,10}$$
  
  that is the heap above but with the node with value 11 replaced by a node with
  value 7. To correct this behaviour, and put the value 7 in it's correct position
  there is a procedure known as "max/min-heapify". Assuming a max-heap, this
  recursive procedure finds the max value between the parent, left and right child,
  say the max value is in the right child, then it swaps the value of right child and
  parent, and call max-heapify again with the right child as parent. In the example above,
  $max(heap[2](7),heap[4](8),heap[5](10)) = heap[5]$, then switch the value of
  $heap[5] = 10$ with $heap[2] = 7$, and repeat. The "$max(heap[5](7),heap[10](10)) = heap[10]$"
  and proceeds by switching the values of $heap[10] = 10$ and $heap[5] = 7$. So finally,
  $heap[10] = 7$ and the node with value 7 will be leaf.


* Bipartiteness
  A bipartite graph is one which all of it's nodes $N$ can be divided into sets
  $A$ and $B$ such that each node in $A$ has a neighbor in $B$ and vice versa.
  Not every graph can be organized in such way, it's possible that for a graph
  $G$ to have one of it's edges connect nodes from $A$ to $A$. But what
  characteristic this graph must have to not be bipartite?
  
  Imagine we have a linear path $p_{1-x} = \{n_1, n_2, ... n_x\}$ that connects
  node $n_1$ to node $n_x$, and we are trying to ensure bipartiteness ,
  if $n_1$ is in $A$, then $n_2$ is necessarily in $B$, and node $n_3$
  in $A$, and so forth. If any node $n_{2*i+1}$ for $i>1$ has an edge
  back to $n_1$ then $G$ is not bipartite. That is, if there is an odd-sized cycle.
  
  To check bipartiteness in a single connected component one could just use BFS
  and assign each node in odd layers to $A$ and those in even layers $B$,
  on the end one could just check for each edge in $G$ if it's ends are in
  different sets. If a node in $L_{2i}$ has an edge to any node in $L_{2j}$ or
  if a node in $L_{2i+1}$ has an edge to a node in $L_{2j+1}$ then there is an
  odd-sized cycle and hence bipartiteness cannot be ensured. We can also attempt
  to prove that the BFS algorithm described above is correct.
  
  *proof:* Imagine there is an odd cycle and the BFS algorithm described above
  claims the graph is bipartite, let's assume w.l.o.g the cycle loops from
  the root $n_i \in L_1$ until $n_j \in L_2$ then back to $n_i$. There is a
  property of BFS trees $T$ which states that every pair of nodes $(x,y)$
  which have an edge between themselves are either in adjacent layers or in the
  same layer in a BFS tree. If for every edge in the odd-sized loop adjacent nodes
  are in adjacent layers then the loop cannot be odd-sized. To check this property
  let's pick the an arbitraty node, $n_h \in L_h$. If $n_h$ only has edges in
  adjacent layer, then it must make the way back to $n_i$ through an edge
  in $L_{h-1}$ or in $L_{h+1}$ yielding a loop of size $h+1+h-1 = 2h$ or
  $h+1+h+1 = 2(h+1)$ which by contradiction is not an odd-sized loop. Therefore
  an odd-sized loop node must have an edge between nodes in the same layer, hence,
  not bipartite as those nodes would be in the same set.
  
* Topological Ordering
   
  Before introducing the idea of topological ordering the meaning of a DAG must
  be clear. A directed acyclical graph (DAG), as the name suggests is a directed
  graph containing no cycles. The idea of a topological ordering is quite
  useful in the context of /dependency networks/ to express the precedence relation
  between nodes. For example, imagine we would like to express the dependencies
  of a particular software package, if we would like to install pandas python
  library then we first need to install pytz, python-dateutil and numpy. However,
  python-dateutil depends on six. And so clearly there is an implicit order
  of which packages should be installed so we could correctly install pandas, this
  order can be represented by an directed edge going from the dependency to the
  package we would like to install, so in the case of pandas: [pytz, pandas],
  [python-dateutil, pandas], [six, python-dateutil], and [numpy, pandas].
  
  
  A topological ordering or sort is a list of nodes in a graph such that
  if we were to install every package in the given order than we would be able
  to all the packages. Or more generally, all an order of nodes such that all
  dependency relations are satisfied. Assuming there are nodes $1,... ,n$ than
  the topological sort would have to enforce that for each $(v_i, v_j)$ that
  $i < j$ . That is, all directed edges point forward and never backwards:

#+begin_src latex :exports results :results raw file :file depgraph.png :output-dir ../img
  \resizebox{0.5\textwidth}{!}{%
    \begin{tikzpicture}[scale=1,samples=5000,nodes={}, ->]
     \node[circle, draw, size=1cm](n0) at (0,4) {six   };
     \node[circle, draw, size=1cm](n1) at (2,4) {date  };
     \node[circle, draw, size=1cm](n2) at (2,2) {pytz  };
     \node[circle, draw, size=1cm](n3) at (2,0) {numpy };
     \node[circle, draw, size=1cm](n4) at (6,2) {pandas};
      \draw[to] (n0) -- (n1) node[none];
      \draw[to] (n1) -- (n4) node[none];
      \draw[to] (n2) -- (n4) node[none];
      \draw[to] (n3) -- (n4) node[none];
   \end{tikzpicture}
       }%
#+end_src

#+RESULTS:
[[file:../img/depgraph.png]]
   
  The topological order for this graph would be:
  
#+begin_src latex :exports results :results raw file :file toporder.png :output-dir ../img
  \resizebox{0.5\textwidth}{!}{%
    \begin{tikzpicture}[scale=1,nodes={}, ->]
     \node[circle, draw, minimum size=1.2cm](n0) at (0,2) {six   };
     \node[circle, draw, minimum size=1.2cm](n1) at (2,2) {date  };
     \node[circle, draw, minimum size=1.2cm](n2) at (4,2) {pytz  };
     \node[circle, draw, minimum size=1.2cm](n3) at (6,2) {numpy };
     \node[circle, draw, minimum size=1.2cm](n4) at (8,2) {pandas};
      \draw (n0) to (n1) node[none];
      \draw (n1) to[bend right=30] (n4) node[none];
      \draw (n2) to[bend left=40] (n4) node[none];
      \draw (n3) to[bend left=30] (n4) node[none];
   \end{tikzpicture}
       }%
#+end_src

#+RESULTS:
[[file:../img/toporder.png]]

  One can quickly check that this order respect the condition mentioned above,
  and that for every edge, the edge always leaves a node before in the topological
  sort than the node it reaches. In fact, one can claim:
  
  //""If G has a topological ordering, then G is a DAG.""//

  *proof:* imagine $G$ has a topological ordering and also contains a cycle.
  Assume there is a directed cycle $v_i, v_{i+1},... , v_{i+n}, v_i$, because there
  is a topological sort, then the edges in the cycle must also be represented
  in the topological sorted graph, as in the example above. Therefore, the position
  of the nodes $i < i+1 < ... < i+n < i$ must exist in the provided ordering,
  which yields a contradiction as $i < i+n < i$.

  We have proof for one direction, however, it is not obvious if the opposite direction
  also holds, i.e.:

  //""If G is a DAG, then G has a topological ordering.""//

  By thinking on the extremes, the first node $n_s$ of the ordering must not have
  any incomming edges, a root node, that is, there must exist no other node $n$ which leads to
  $n_s$. Additionally, the last node $n_l$ of the ordering must have no outgoing edges
  to a node $n_i$, otherwise, $i > s$ and hence $n_s$ is not the last node, that is a leaf.
  Therefore we have to prove that:

  //""If G is a DAG, then G has a root and G has a leaf""//

  *proof:* let's first prove that G has a root, and assume that G is a DAG, and
  that there for every $n$ in G, $n$ has an incomming node. Imagine we have a DAG
  with $k$ nodes, and we pick any node $n_i$ of G, then this node must have an
  incomming node $n_{i+1}$. Now, $n_{i+1}$ must have an incomming node and it must
  not be $n_i$, as G is a DAG, say the incomming node is $n_{i+2}$. This leads
  us to be able to pick infinitely many nodes out of G, which are not previously
  seen, which clearly contradicts the fact that G has a finite size $k$. Hence,
  G must have a root. The same proof by contradiction can be applied by outgoing
  edges of an initial node $n_i$, in fact, it doesn't really matter if we are
  interested in outgoing or incomming edges, but the fact that we cannot draw infinte
  outgoing unseen edges from G, when G is a DAG.
  

  It still left to show that being a DAG implies having a topological order. It
  is possible to prove that if G is a DAG and has a root node than it also has a
  topological ordering by induction on the size of the DAG.

  *proof:* If G is a DAG with one or two nodes, it clearly has a topological order.
  The induction hypothesis states that a DAG with $n$ nodes have a topological order.
  Thus, it is left to prove in the induction step if a DAG G with $n+1$ nodes
  also have such sort. G must have a root as shown before, so we have the first
  node of the sort, the rest of the graph G $-$ {$n_{root}$} has size $n$ and as mentioned
  in the induction hypothesis has a topological order. Therefore, G has a topological
  order.
  
* Red-Black Trees
  Firstly, the concept of binary search trees must be clear, i.e. binary trees
  which for each node, all of it's left descendents have values smaller than
  the node's value and all it's right descendents have values bigger than the
  node's values. This structure makes searching a node an $O(log n)$ operation,
  as we are breaking the search space in half every time we compare the searched
  value with the current node value.
  Red-Black trees are binary search trees with an additional bit to represent
  the color of the nodes, 0 or 1, red or black. There are five properties of such
  trees.
  1. Every node must have a color.
  2. The root is also black.
  3. Every leaf is black.
  4. If a node is red, it's two descendents must be black.
  5. For every path leaving a parent node until a leaf, there is the same count
    of black nodes, ignoring the parent node values.

Bellow there is an exaple of such tree:
#+begin_src latex :exports results :results raw file :file simplerbtree.png :output-dir ../img
  \resizebox{0.4\textwidth}{!}{%
    \begin{tikzpicture}[scale=1,nodes={draw, circle}, ->]
      \node{10}
      child { node[red]{4}
	child { node {3} child {node[black] {n}}}
	child { node {6}
	 child { node[red] {5} child {node[black] {n}}}
	 child { node[red] {8} child {node[black] {n}}}
         }
      }
      child[missing]
      child { node {12}
	child { node[red] {11} child {node[black] {n}}}
	child { node[red] {14} child {node[black] {n}}}
      };
   \end{tikzpicture}
       }%
#+end_src

#+RESULTS:
[[file:../img/simplerbtree.png]]

Notice that there is a node $n$, or nil, following each leaf. This special black
node don't have any value, it's just a way to assure that all leaves are black,
some prefer to draw two $n$ nodes as this is a binary tree, or a single node at
the bottom where each leaf point to. 

Some properties mentioned above implies height restrictions on black-red trees.
Assume, that a "black height" $bh_n$ is the count of black nodes from a particular node
$n$ to any of it's leaves. For instance the $bh_{10}=2$ as if we take a the path
${10, 12, 11, n}$ there are two black nodes disregarding the color of $n_10$. As
prop. 5 ensures that regardless of the path from $n_10$ the black count will be
the same, you can quickly check this is the case, although it is not necessary.

Let's prove that any node with a height $h$ has a black height $\ge h/2$.

*proof:* When considering any path $p$ from a node $n_i$ to some leaf with height $h_p$
then this path should contain either only black nodes, or a both red and black nodes. If
there are red nodes, then at most, half of the path are consists of red nodes, given prop. 4.
Therefore, the count of black nodes in any path $p$ is at least $h_p/2$.

* References
  + Kleinberg, J., Tardos, &E. (2006). Algorithm Design. Addison Wesley.
  + Cormen, T. H., & Cormen, T. H. (2001). Introduction to algorithms. Cambridge, Mass: MIT Press.

