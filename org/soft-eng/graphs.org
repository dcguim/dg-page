#+TITLE: Advanced graph topics
#+SUBTITLE: Software Engineering Topics
#+INCLUDE: "../navbar.html" export html
#+OPTIONS: toc:nil
#+OPTIONS: num:nil
#+LaTeX_HEADER: \usepackage{tikz}
#+LATeX_HEADER: \usepackage{pgfplots}

* Connectivity
  The form and intensity which nodes are connected to each other is an important
  factor when designing graph algorithms. Usually, a graph is implemented either
  as an adjacency list or a matrix, if every node  is connected to each other
  (the graph is /strongly/ connected), then one might prefer a $\Omega(n^2)$
  matrix representation as the presence of edges can be fetched in $\Omega(1)$,
  retrieving a current node's neighbor is returned in $\Omega(n)$.

  The degree $d_a$, is the notation measures how connected is node $a$. For
  /sparse/ graphs, when the degrees of the nodes are usually smaller than $n$
  an $\Omega(n+m)$ adjacency list representation is better fit. Notice, in such
  lists, the sum of all degrees for every node, assuming undirected edges, is:
  \[ \sum_{i \in N} d_i = 2m \]

  As the same edge $(a, b)$ exists in $adj[a]$ and $adj[b]$. Retrieving
  neighbors of $a$ can be made in $\Omega(d_a)$, by simply looking up $adj[a]$ and
  similarly for checking the presence of an edge. Notice, that depending on how
  sparse a graph is traversing it can amount to a significant time reduction.
  Imagine in a tree-traversal algorithm, the neighbors of each node are retrieved,
  then we would have $\Omega(m) = \Omega(n)$ time for adjacency lists while
  $\Omega(n^2)$ for matrixes.

  For a practical example on the complexity implications of the two implementations
  the LeetCode solution and discution for [[https://leetcode.com/problems/frog-position-after-t-seconds/][Frog Position After T Seconds - 1377]]
  can be found in the [[file:treesgraphs.html][Trees and graphs]] page. 

** Connected components
  The definition of a connected component is the set of nodes reacheable from a
  particular initial node $n_i$, one can also think about a connected component as
  the set of nodes in a binary search tree produced by a complete execution of BFS
  or DFS algorithm. Another way to understand how one can explore nodes on a
  graph $G=(E, N)$ forming a connected component $C_{0}$ starting at node $0$ is:
  
  #+begin_src python
  def explore_graph(E, N):
    C = {0}
    while ((a, b) in E and
  	 a in C and
  	 b not in C):
      C.append(b)
  #+end_src
    
  Notice we are also solving the connectivity problem, by defining every node $i$
  that is reachable from node $0$. Notice, it is also trivial to define the path
  itself that lead to node $i$, as we know at which iteration $i$ was added to $C$
  and therefore we also know the neighboring node which was in $C$, so we can always
  trace back to node $0$ by keeping the /"parent"/ of each node in $C$. The order
  of which the edges $(a,b)$ will be fetched from the graph $G$ can be defined
  by DFS or BFS algorithm.
  
  We mentioned about connected components relative to a starting node, but what
  about the set of connected components of a graph. One can say:
  
    //""For any two nodes $a$ and $b$ in a graph, their connected components are
    either identical or disjoint""//
  
  *proof:* assume there are two nodes $a$ and $b$ which their connected
  components are different and connected. That means that starting from $a$, we would
  obtain $C_a$ and starting from $b$ we would obtain $C_b$, if they are different
  that means that there are nodes that exist at least one node $c$ which is in
  w.l.o.g. in $C_a$ but not in $C_b$. That means, there is no path from $b$ to
  $c$, however, as there is a path from $b$ to $a$ and from $a$ to $c$, then there
  must be a path from $b$ to $c$, which is a contradiction.

** Complexity in Graph Algorithms
  Normally, the running time of graph algorithms are expressed in terms of
  $(n=|N|, e=|E|)$ for $G(N,E)$. However, it is not always obvious which complexity
  to prioritize, will an algorithm in $O(n^3)$ or $O(e^2)$ run faster? Well, it
  depends on the relationship between $n$ and $e$. If we consider a single
  connected component, there should be at least $n-1$, and at most $C^{n}_{2} < n^2$
  edges. Therefore, for trees $O(e^2)$ is better, while for strongly connected
  graphs $O(n^3)$ is.

** Bipartiteness
   A bipartite graph is one which all of it's nodes $N$ can be divided into sets
   $A$ and $B$ such that each node in $A$ has a neighbor in $B$ and vice versa.
   Not every graph can be organized in such way, it's possible that for a graph
   $G$ to have one of it's edges connect nodes from $A$ to $A$. But what
   characteristic this graph must have to not be bipartite?

   Imagine we have a linear path $p_{1-x}$ that connects node 1 to node $x$, and
   we are trying to ensure bipartiteness , if $n_1$ is in $A$, then $n_2$ is
   necessarily in $B$, and node $n_3$ in $A$, and so forth. If any node
   $n_{2*i+1}$ for $i>1$ has an edge back to $n_1$ then $G$ is not bipartite. That
   is, if there is an odd-sized cycle.

   To check bipartiteness in a single connected component one could just use BFS
   and add assign each node in odd layers to $A$ and those in even layers $B$,
   on the end one could just check for each edge in $G$ if it's ends are in
   different sets. If a node in $L_{2i}$ has an edge to any node in $L_{2j}$ or
   if a node in $L_{2i+1}$ has an edge to a node in $L_{2j+1}$ then there is an
   odd-sized cycle and hence bipartiteness cannot be ensured. We can also attempt
   to prove that the BFS algorithm described above is correct.

   *proof:* Imagine there is an odd cycle and the BFS algorithm described above
   claims the graph is bipartite, let's assume w.l.o.g the cycle loops from
   the root $n_i \in L_1$ until $n_j \in L_2$ then back to $n_i$. There is a
   property of BFS trees $T$ which states that every pair of nodes $(x,y)$
   which have an edge between themselves are either in adjacent layers or in the
   same layer in a BFS tree. If for every edge in the odd-sized loop the nodes
   are in adjacent edges then the loop cannot be odd-sized. To check this property
   let's pick the node furthest away from $n_i$, $n_h \in L_h$. If $n_h$ only
   has nodes with adjacent edges and is the highest node, then it must make the
   way back to $n_j$ through an edge in $L_{h-1}$ yielding a loop of size
   $h+1+h-1 = 2h$ which by contradiction is not an odd-sized loop. Therefore
   an odd-sized loop node must have an edge between nodes in the same layer, hence,
   not bipartite as those nodes would be in the same set.
  
** Topological Ordering
   
   Before introducing the idea of topological ordering the meaning of a DAG must
   be clear. A directed acyclical graph (DAG), as the name suggests is a directed
   graph containing no cycles. The idea of a topological ordering is quite
   useful in the context of /dependency networks/ to express the precedence relation
   between nodes. For example, imagine we would like to express the dependencies
   of a particular software package, if we would like to install `pandas` python
   library then we first need to install pytz, python-dateutil and numpy. However,
   python-dateutil depends on six. And so clearly there is an implicit order
   of which packages should be installed so we could correctly install pandas, this
   order can be represented by an directed edge going from the dependency to the
   package we would like to install, so in the case of pandas: [pytz, pandas],
   [python-dateutil, pandas], [six, python-dateutil], and [numpy, pandas].


   A topological ordering or sort is a list of nodes in a graph such that
   if we were to install every package in the given order than we would be able
   to all the packages. Or more generally, all an order of nodes such that all
   dependency relations are satisfied. Assuming there are nodes $1,... ,n$ than
   the topological sort would have to enforce that for each $(v_i, v_j)$ that
   $i<j$. That is, all edges point forward and never back:

#+begin_src latex :exports results :results raw file :file depgraph.png :output-dir ../img
  \resizebox{0.5\textwidth}{!}{%
    \begin{tikzpicture}[scale=1,samples=5000,nodes={}, ->]
     \node[circle, draw, minimum size=1.2cm](n0) at (0,4) {six   };
     \node[circle, draw, minimum size=1.2cm](n1) at (2,4) {date  };
     \node[circle, draw, minimum size=1.2cm](n2) at (2,2) {pytz  };
     \node[circle, draw, minimum size=1.2cm](n3) at (2,0) {numpy };
     \node[circle, draw, minimum size=1.2cm](n4) at (6,2) {pandas};
      \draw[to] (n0) -- (n1) node[none];
      \draw[to] (n1) -- (n4) node[none];
      \draw[to] (n2) -- (n4) node[none];
      \draw[to] (n3) -- (n4) node[none];
   \end{tikzpicture}
       }%
#+end_src

#+RESULTS:
[[file:../img/depgraph.png]]
   
  The topological order for this graph would be:
  
#+begin_src latex :exports results :results raw file :file toporder.png :output-dir ../img
  \resizebox{0.5\textwidth}{!}{%
    \begin{tikzpicture}[scale=1,nodes={}, ->]
     \node[circle, draw, minimum size=1.2cm](n0) at (0,2) {six   };
     \node[circle, draw, minimum size=1.2cm](n1) at (2,2) {date  };
     \node[circle, draw, minimum size=1.2cm](n2) at (4,2) {pytz  };
     \node[circle, draw, minimum size=1.2cm](n3) at (6,2) {numpy };
     \node[circle, draw, minimum size=1.2cm](n4) at (8,2) {pandas};
      \draw (n0) to (n1) node[none];
      \draw (n1) to[bend right=30] (n4) node[none];
      \draw (n2) to[bend left=40] (n4) node[none];
      \draw (n3) to[bend left=30] (n4) node[none];
   \end{tikzpicture}
       }%
#+end_src

#+RESULTS:
[[file:../img/toporder.png]]

  One can quickly check that this order respect the condition mentioned above,
  and that for every edge, the edge always leaves a node before in the topological
  sort than the node it reaches. In fact, one can claim:
  
  //""If G has a topological ordering, then G is a DAG.""//

  *proof:* imagine $G$ has a topological ordering and also contains a cycle.
  Assume there is a directed cycle $v_i, v_{i+1},... , v_{i+n}, v_i$, because there
  is a topological sort, then the edges in the cycle must also be represented
  in the topological sorted graph, as in the example above. Therefore, the position
  of the nodes $i < i+1 < ... < i+n < i$ must exist in the provided ordering,
  which yields a contradiction as $i < i+n < i$.

* References
  + Kleinberg, J., Tardos, &E. (2006). Algorithm Design. Addison Wesley.
